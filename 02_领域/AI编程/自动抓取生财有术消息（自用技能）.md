下面把“部署位置 + 改代码后的重启/发布 + 运维命令”补成一份更细的后期维护文档（偏 runbook 风格，照着做就行）。你可以直接复制到飞书/Obsidian。

---

# 生财阅读器 后期维护文档（运维版）

## 0. 服务清单与职责

### A. Scraper 服务（Playwright）

- **职责**：带登录态抓取精华帖/风向标列表与详情，提供 HTTP 接口给 n8n 调用
    
- **对外接口**（示例）：
    
    - `GET /health` 健康检查
        
    - `POST /crawl` 抓取（传 startISO/endISO/maxLinks）
        
- **部署方式**：Docker 容器（通常由 docker compose 管理）
    
- **端口**：宿主机 `3005` → 容器 `3000`（你现在就是这个映射）
    

### B. n8n

- **职责**：定时触发、调用 scraper、写入飞书多维表格、生成卡片、推送机器人
    
- **部署方式**：Docker 容器（compose 管理）
    
- **注意**：大多数逻辑改动发生在 n8n 节点里，不一定需要重启 n8n 容器
    

### C. 飞书多维表格（Bitable）

- **职责**：数据仓库（去重、查询、回溯）
    
- **维护点**：字段名变更会导致写入失败
    

### D. 飞书群机器人 Webhook

- **职责**：推送“日报卡片”
    
- **维护点**：卡片 body 必须是合法 JSON 字符串（你已用 `JSON.stringify` 解决）
    

---

## 1. 部署位置约定（建议固定，避免以后找不到）

> 下面给一个强烈建议的“标准目录结构”。如果你现在不是这个路径，也没关系，按你实际路径替换即可。

### 1.1 建议目录

在服务器上固定一个项目目录，例如：

- `/root/scys-reader/` 或 `/opt/scys-reader/`
    

目录结构建议：

```
scys-reader/
  docker-compose.yml
  scraper/
    server.js
    package.json
    ...
    state/
      storageState.json
  n8n/
    (可选：自定义配置、备份)
```

### 1.2 怎么确认你现在部署在哪里

在服务器执行：

```bash
pwd
ls -la
```

如果你是用 compose 启动的，一般当前目录会看到 `docker-compose.yml` 或 `compose.yaml`。

如果找不到项目目录，用这招定位 compose 文件：

```bash
find / -maxdepth 4 -name "docker-compose.yml" 2>/dev/null
find / -maxdepth 4 -name "compose.yaml" 2>/dev/null
```

---

## 2. Scraper 服务部署与重启（最常用）

### 2.1 查看 scraper 是否在跑

```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -i scraper
```

你之前看到类似：

- `0.0.0.0:3005->3000/tcp`
    

说明外部访问 3005，容器内部监听 3000。

### 2.2 健康检查

在服务器上执行：

```bash
curl -sS http://localhost:3005/health
```

预期返回类似：

```json
{"ok":true}
```

> 如果这里连不上：

- 先确认容器在不在
    
- 再确认端口映射
    
- 最后看容器日志（见 2.4）
    

### 2.3 改了 scraper 代码后怎么生效（两种情况）

#### 情况 A：你是“镜像构建式”（Dockerfile 构建）

改了 `server.js`/依赖后，必须 **重新 build**：

**方式 1：用 docker compose（推荐）**  
在项目目录（有 docker-compose.yml 的地方）执行：

```bash
docker compose up -d --build scraper
```

如果你的服务器 docker 还是老版本（只有 `docker-compose`），用：

```bash
docker-compose up -d --build scraper
```

> 你之前遇到过 `unknown shorthand flag: 'd' in -d`，那通常是因为你敲成了 `docker compose up -d --build` 但系统把它当成别的命令解析。  
> 解决方式：先确认有没有 compose 插件：

```bash
docker compose version
docker-compose version
```

哪个有就用哪个。

#### 情况 B：你是“挂载源码式”（volume 挂载）

如果 compose 里把本机 `scraper/` 挂到容器 `/app`，那改代码后只需要 **重启容器**：

```bash
docker compose restart scraper
# 或
docker-compose restart scraper
```

> 你可以打开 `docker-compose.yml`，看有没有类似：

```yaml
volumes:
  - ./scraper:/app
```

有就是挂载式。

---

### 2.4 查看 scraper 日志（定位抓取为空、登录失效等）

```bash
docker logs -f --tail=200 scys-reader-scraper-1
```

常看三类信息：

- 是否访问到了正确列表页（你日志里有 `LIST actualUrl:`）
    
- 是否被重定向到登录页（title 变了或 URL 变了）
    
- Playwright 浏览器缺失/版本不匹配（会直接报 executable doesn’t exist）
    

---

### 2.5 重新生成与替换 storageState.json（登录态）

#### storageState 是否会失效？

会，常见原因：

- token/会话过期
    
- 异地登录、风控
    
- 网站更新导致 cookie 结构变化
    

#### 替换步骤（推荐固定路径）

1. 把最新的 `storageState.json` 放到服务器，例如：
    
    - `/root/scys-reader/scraper/state/storageState.json`
        
2. 如果你用 volume 挂载 state 目录，直接覆盖文件即可
    
3. 重启 scraper：
    

```bash
docker compose restart scraper
# 或 docker-compose restart scraper
```

#### 验证登录态是否有效

跑一次 `/crawl`（范围给大一点，maxLinks 小一点）：

```bash
curl -sS -X POST http://localhost:3005/crawl \
  -H "Content-Type: application/json" \
  -d '{"startISO":"2026-01-14T00:00:00+08:00","endISO":"2026-01-14T23:59:59+08:00","maxLinks":3}'
```

如果 `items` 为空且日志显示标题正常但抓不到内容，通常是登录态或列表解析规则变了。

---

## 3. n8n 部署、重启与发布

### 3.1 n8n 容器状态

```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -i n8n
```

### 3.2 n8n 什么时候需要重启？

- ✅ 修改了 docker 环境变量（例如 `FEISHU_APP_ID`）需要重启容器
    
- ✅ 升级 n8n 镜像版本需要重启
    
- ❌ 只是在 n8n UI 里改工作流节点，一般不需要重启
    

### 3.3 重启 n8n

```bash
docker compose restart n8n
# 或 docker-compose restart n8n
```

### 3.4 备份工作流（强烈建议）

在 n8n UI：

- Workflows 列表导出 JSON
    
- 或把关键工作流复制一份命名为 `xxx-backup-YYYYMMDD`
    

---

## 4. 宝塔面板下的操作说明（你这种环境很常用）

### 4.1 重启容器（推荐用宝塔 Docker 管理器）

宝塔面板：

- Docker → 容器 → 找到 `scys-reader-scraper-1` → 重启
    
- 同理可重启 n8n 容器
    

### 4.2 修改 compose 文件

宝塔：

- 文件 → 找到项目目录 → 编辑 `docker-compose.yml`
    
- 修改后回到 Docker 管理器重启容器  
    如果改了镜像或构建，需要重新部署（等价于 `up -d --build`）
    

> 小提醒：宝塔里“重启容器”不会重新 build 镜像，改代码但没挂载时必须 build。

---

## 5. 常见故障与快速处理（带明确动作）

### 5.1 抓取为空（items: []）

**排查顺序**

1. `curl http://localhost:3005/health` 是否 ok
    
2. `docker logs scraper` 看是否重定向登录页
    
3. 检查 `storageState.json` 是否存在、路径是否正确
    
4. 网站结构变化：列表链接规则变了 or API 参数变了
    

**常用修复**

- 更新 storageState
    
- 调整列表解析规则或改用 API 抓取（你前面分析过 searchTopic/topicDetail 接口）
    

---

### 5.2 写入多维表格失败

**排查顺序**

1. `tenant_access_token` 是否取到（n8n 节点输出）
    
2. 飞书应用是否授权该 Base
    
3. `records` 结构是否为数组、且每项有 `fields`
    

**常用修复**

- n8n “批量新增记录”用 JSON Parameters 传 `records={{$json.records}}`（避免被字符串化）
    
- 字段名变更要同步改映射（尤其中文字段）
    

---

### 5.3 卡片推送失败（400 Bad request）

你已经解决了核心坑：Raw + Expression 返回对象会变成 `[object Object]`，必须 `JSON.stringify`。  
后续还要注意：

- `elements` 里不要放 `{tag:"plain_text"}` 这种 block  
    正确用法是 `div.text` 里 `plain_text` 或 `lark_md`
    
- 卡片内容太长要截断（SAFE_MAX）
    

---

## 6. 发布流程（建议固定成 SOP）

### 6.1 修改 scraper 代码后的 SOP

1. 本地改代码并测试（能跑 `/crawl`）
    
2. 上传/提交到服务器目录
    
3. 服务器：
    
    - 如果构建式：`docker compose up -d --build scraper`
        
    - 如果挂载式：`docker compose restart scraper`
        
4. `curl /health`
    
5. `curl /crawl` 小范围验证
    
6. 看日志 1 分钟确认无报错
    

### 6.2 修改 n8n 工作流后的 SOP

1. 先在 n8n 手动执行一次（用当天日期）
    
2. 检查：
    
    - 多维表格是否写入
        
    - 卡片是否可发
        
3. 执行成功后再启用 Cron
    
4. 导出工作流备份 JSON
    

---

## 7. “必须记录”的关键参数（以后迁移不慌）

建议在文档最后放一个配置表（示例）：

- 项目目录：`/root/scys-reader`
    
- Scraper 容器名：`scys-reader-scraper-1`
    
- Scraper 端口：`3005->3000`
    
- Scraper 健康检查：`http://localhost:3005/health`
    
- storageState 路径：`/root/scys-reader/scraper/state/storageState.json`
    
- n8n 容器名：`n8n-1`
    
- Bitable Base/表/视图链接：`BITABLE_VIEW_URL=...`
    
- 机器人 Webhook：`FEISHU_WEBHOOK=...`（建议放环境变量，不要写文档明文）
    

---

